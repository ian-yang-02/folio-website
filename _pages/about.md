---
layout: about
title: about
permalink: /
subtitle: <i>Georgia Institute of Technology</i>, <i>Carnegie Mellon University</i>, <i>University of Minnesota</i>

profile:
  align: right
  image: IMG_9550.jpg
  image_circular: false # crops the image to make it circular
  address: >
    <a href="https://drive.google.com/file/d/17vQDXQGPWrVAgIxhbktTf0GM-pUstTSP/view?usp=sharing">CV</a> / <a href="https://scholar.google.com/citations?user=7A4ZCDoAAAAJ&hl=en">Google Scholar</a>

news: false  # includes a list of news items
latest_posts: false  # includes a list of the newest posts
selected_papers: false # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

Hello! I recently completed my undergraduate degree in computer science at Georgia Tech. I also dabble in mathematics, philosophy, and linguistics.

Broadly, I'm interested in understanding the sociocultural implications of language technologies and how to minimize non-normative behaviors in intelligent agents.

My current research at Georgia Tech is in NLP techniques applied to the [value alignment](https://en.wikipedia.org/wiki/AI_alignment) problem, advised by [Mark Riedl](http://eilab.gatech.edu/mark-riedl.html).

I'm also a research assistant at Carnegie Mellon University, advised by [Norman Sadeh](https://www.normsadeh.org/). At CMU I'm interested in NLP applied to data security and [privacy](https://usableprivacy.org/).

Most recently, I have been collaborating with [Mingyi Hong](https://people.ece.umn.edu/~mhong/mingyi.html) and [Dongyeop Kang](https://dykang.github.io/) at the University of Minnesota. At UMN I am working on dense reward shaping for RLHF alignment tasks.

Previously, I was a research assistant at The Ohio State University (advised by [Dong Xuan](https://scholar.google.com/citations?hl=en&user=11NcM2EAAAAJ&view_op=list_works&sortby=pubdate)), and a Full-Stack Software Engineering Intern at [FlightBridge](https://flightbridge.com/).
